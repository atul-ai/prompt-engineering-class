{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pQqDCng2n2bY",
        "rwS8sLWmnrEb",
        "ZfJrFhTGnk1-",
        "iaeIaFDvnau4"
      ],
      "authorship_tag": "ABX9TyPCyvcq+DOFIp7u+ruZVLH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atul-ai/prompt-engineering-class/blob/main/WordEmbeddingsExamples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pre-trained Word Embeddings"
      ],
      "metadata": {
        "id": "r0sc7jRmmuBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "First, let's install and import the necessary libraries:\n"
      ],
      "metadata": {
        "id": "5DysK-hFm0Zs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LIrCxEo_uC2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a9ccdc-1654-4b9b-d073-35eef4e9a08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch gensim numpy scipy matplotlib\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Sample Sentences\n",
        "\n",
        "We'll use these sentences for our demonstrations:\n",
        "\n"
      ],
      "metadata": {
        "id": "hlRW1aEem7_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"Dogs are man's best friend.\",\n",
        "    \"It's raining cats and dogs.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"A picture is worth a thousand words.\",\n",
        "    \"Don't judge a book by its cover.\",\n",
        "    \"The apple doesn't fall far from the tree.\",\n",
        "    \"Time flies like an arrow.\",\n",
        "    \"All that glitters is not gold.\"\n",
        "]"
      ],
      "metadata": {
        "id": "AQ8MMjDBm7LR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. BERT Embeddings\n",
        "\n",
        "Let's use BERT to get contextual embeddings:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w2l82YDmnLoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def get_bert_embedding(sentence):\n",
        "    inputs = bert_tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "# Get BERT embeddings for all sentences\n",
        "bert_embeddings = [get_bert_embedding(sent) for sent in sentences]\n",
        "\n",
        "print(\"BERT embedding shape:\", bert_embeddings[0].shape)\n",
        "print(bert_embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qLI9y24En5US",
        "outputId": "491bc98b-71f5-4ce7-a931-6914f200483f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT embedding shape: (768,)\n",
            "[-1.81803331e-01 -2.66178459e-01 -2.18866497e-01  2.10887864e-01\n",
            "  2.84733891e-01 -1.71848714e-01 -1.65881395e-01  5.09736776e-01\n",
            " -1.27144992e-01 -1.69706762e-01  3.03522944e-02 -4.69049990e-01\n",
            " -3.58982049e-02  1.33982167e-01 -1.17660999e-01 -2.40768567e-01\n",
            "  1.20715722e-01  5.91536611e-02 -3.91021132e-01  1.07807025e-01\n",
            "  2.31676280e-01 -2.06526875e-01 -5.21814585e-01  9.92321670e-02\n",
            "  2.94130504e-01 -2.43794993e-01  7.10860491e-02 -1.43256009e-01\n",
            " -5.07237762e-02 -2.29964089e-02  2.10268632e-01 -5.67063875e-02\n",
            " -1.49750292e-01 -2.79531151e-01  5.43978959e-02 -8.85230005e-02\n",
            "  2.97807395e-01  3.17300677e-01 -5.46831906e-01  2.36233160e-01\n",
            " -3.62854600e-01 -1.80200204e-01  2.56574489e-02  5.81901133e-01\n",
            "  4.08479095e-01 -2.32060194e-01  4.06711966e-01 -2.07815111e-01\n",
            "  6.34876370e-01  1.69491053e-01 -6.29979789e-01  3.35770339e-01\n",
            " -2.82218382e-02  1.09117158e-01 -3.31124179e-02  6.67784333e-01\n",
            "  2.23814592e-01 -3.44666481e-01 -1.05968425e-02  3.83142501e-01\n",
            " -6.36851341e-02  4.34456497e-01  1.94776952e-01 -5.21952987e-01\n",
            " -2.37982929e-01  4.48994905e-01 -6.22288920e-02  2.04688951e-01\n",
            " -3.88028085e-01  2.68625438e-01 -4.25302237e-01 -3.82214427e-01\n",
            " -1.11827165e-01  3.45197953e-02  3.54905501e-02  3.39356437e-02\n",
            "  1.33732818e-02  3.40563416e-01  3.35378915e-01  7.53131183e-03\n",
            " -2.49093533e-01  7.33089089e-01 -5.03933877e-02  4.04127419e-01\n",
            "  1.59237921e-01 -9.60056186e-02 -3.55443120e-01 -3.25212508e-01\n",
            " -4.93523121e-01  3.95581692e-01 -4.10278440e-01 -2.25011483e-02\n",
            " -3.11504781e-01  5.49612880e-01 -3.41952429e-03  3.42987806e-01\n",
            "  1.41003251e-01 -1.24014407e-01  1.81178987e-01  3.11869770e-01\n",
            "  2.79588819e-01 -4.70751747e-02  3.93809170e-01  5.56411266e-01\n",
            " -1.96299136e-01 -5.35615146e-01  2.22814620e-01 -7.37315044e-02\n",
            " -3.07359755e-01  5.43866083e-02 -7.68311769e-02 -4.48824286e-01\n",
            "  3.40529680e-01 -9.09100398e-02 -3.07974555e-02  7.99977958e-01\n",
            " -1.21648908e-01  1.05522228e-02 -2.74471641e-01  1.52627110e-01\n",
            " -6.94588348e-02 -3.78509313e-01 -2.94704214e-02  6.55964136e-01\n",
            "  1.07202381e-02  9.96043012e-02 -2.27195740e-01 -1.32913822e-02\n",
            "  1.28191248e-01 -5.48755467e-01  3.88631165e-01  6.16572618e-01\n",
            "  1.81633949e-01 -7.45443106e-01 -1.93069264e-01  6.91518068e-01\n",
            "  4.85391974e-01  2.77656149e-02 -8.77215862e-01  1.30447209e-01\n",
            "  2.88062304e-01 -1.05067171e-01  2.22190410e-01  1.78360358e-01\n",
            "  7.53507376e-01  2.57318616e-01 -8.67746770e-02 -3.67715031e-01\n",
            "  6.59459010e-02  2.51723081e-01  2.38041371e-01 -5.29631376e-02\n",
            " -1.41639963e-01 -2.69344300e-01 -3.55021596e-01 -4.66307849e-02\n",
            " -2.17600167e-01  2.84317762e-01  2.72324413e-01  1.28194273e-01\n",
            "  4.19042051e-01 -4.29880768e-01 -1.37266874e-01  1.26753658e-01\n",
            " -6.39671460e-02  2.63348907e-01 -5.54882661e-02  4.22068596e-01\n",
            " -4.13663173e-03  3.31085116e-01 -4.34915453e-01  2.24463642e-01\n",
            "  9.79767263e-01 -3.11588168e-01 -2.77606338e-01 -1.31628618e-01\n",
            " -1.91543728e-01 -2.14616477e-01 -3.63088608e-01  1.83860585e-01\n",
            " -1.44435191e+00  2.02774510e-01  3.55377406e-01  5.04778251e-02\n",
            "  2.46242493e-01 -2.56365895e-01  6.28829360e-01 -7.82853365e-01\n",
            " -3.59274417e-01  3.17806572e-01  1.17422789e-01 -4.97518420e-01\n",
            " -5.93803585e-01  1.62015930e-01  5.06631434e-01 -6.30189121e-01\n",
            " -5.55645883e-01 -7.16491461e-01 -2.27507904e-01 -2.05289468e-01\n",
            "  1.05079666e-01 -5.52608430e-01  3.38650495e-01  3.14903706e-01\n",
            "  2.37462595e-01  2.09144294e-01 -1.79398432e-01 -2.92228311e-01\n",
            " -2.80910969e-01  4.06361043e-01 -3.76648098e-01  4.41915005e-01\n",
            "  2.35227987e-01  4.70206887e-01  2.82958895e-01 -3.05464864e-02\n",
            "  1.80783004e-01  2.16747686e-01 -2.19411090e-01  2.04662129e-01\n",
            "  1.84582807e-02  2.16194287e-01 -6.35322273e-01  5.76749682e-01\n",
            " -6.32334799e-02  1.31033516e+00 -9.14574042e-03 -1.55452654e-01\n",
            " -2.51811147e-01  6.33001745e-01  2.13941615e-02 -1.05368800e-03\n",
            "  5.09585798e-01  5.61810553e-01 -4.26638514e-01 -2.32511312e-01\n",
            " -4.55272198e-01 -2.18326598e-01  5.15276492e-02 -1.37410611e-01\n",
            " -1.29983231e-01  2.56719708e-01  9.57637668e-01 -1.82429716e-01\n",
            "  1.45051241e-01  9.24586058e-02  1.79219082e-01  3.99965465e-01\n",
            " -3.51136416e-01 -4.96385723e-01  2.41902038e-01 -6.41448617e-01\n",
            "  9.34770256e-02 -8.80535960e-01 -4.09722328e-01 -3.36816609e-01\n",
            " -5.16313434e-01  7.59975612e-02  5.78519376e-03  2.62645721e-01\n",
            "  5.21016061e-01 -2.10656095e-02  8.00293326e-01 -2.89895535e-01\n",
            " -3.59908044e-02 -8.04589987e-02  5.17029524e-01  1.70006305e-01\n",
            " -3.10777813e-01 -3.48545432e-01  3.35561275e-01 -3.42847258e-01\n",
            "  3.62085700e-01  1.61680244e-02 -4.80383247e-01 -2.88543433e-01\n",
            "  3.74987304e-01 -1.51530758e-01  1.42281473e-01 -6.91912115e-01\n",
            "  2.23806307e-01  5.06316304e-01 -8.15070868e-01  6.11691065e-02\n",
            "  1.51720449e-01 -6.83611929e-01 -9.43521708e-02 -3.92237958e-03\n",
            " -7.76263401e-02 -3.54719371e-01  1.69559550e-02  5.99293172e-01\n",
            " -1.64879024e-01 -3.39551151e-01 -5.27249515e-01  7.47078806e-02\n",
            "  8.24144483e-02  4.44488049e-01  2.63059974e-01 -8.62175524e-02\n",
            " -6.44346848e-02 -1.55229941e-01  5.77234961e-02  3.48094136e-01\n",
            " -7.34490156e-02 -1.62596822e-01 -8.10585022e-02 -1.03864722e-01\n",
            " -2.80102825e+00  2.01867864e-01  1.97378397e-01 -8.15332234e-02\n",
            "  5.92006743e-01 -6.28030300e-03 -1.95551813e-01 -3.01122785e-01\n",
            " -8.33163738e-01  2.21879080e-01  1.17442660e-01 -4.29469854e-01\n",
            "  6.97562993e-01  4.47822362e-01  3.71654481e-01 -4.11858618e-01\n",
            "  1.92529678e-01 -3.38231921e-01 -1.96670234e-01  2.88100034e-01\n",
            " -4.42284912e-01 -6.77979112e-01 -1.96881041e-01 -7.52712250e-01\n",
            "  2.81450838e-01  9.58014190e-01  4.23320308e-02  2.10862324e-01\n",
            " -5.87791204e-01 -2.99297065e-01 -1.38128236e-01 -6.72754943e-02\n",
            "  2.90394962e-01 -2.35578954e-01  1.50748864e-01 -1.01116121e-01\n",
            "  2.68096060e-01 -2.02807426e-01  5.88221550e-02  2.76382387e-01\n",
            " -1.93809792e-01  1.43049628e-01  2.43231460e-01  2.81829506e-01\n",
            "  7.67593563e-01  2.18486860e-02 -3.22852790e-01 -6.39840364e-01\n",
            "  5.15586957e-02  5.07123828e-01  1.97139099e-01  2.02281903e-02\n",
            " -4.11990523e-01  2.37398269e-03  2.05670953e-01 -1.78101212e-01\n",
            "  3.62533778e-01 -1.22722387e-01 -5.15437841e-01 -3.32565784e-01\n",
            "  3.04173566e-02 -4.23421711e-01 -5.41194864e-02  5.02142668e-01\n",
            "  1.83670416e-01 -2.78643191e-01 -4.02694941e-01 -5.21949649e-01\n",
            "  2.95177191e-01  2.61269927e-01 -1.14433460e-01 -2.18128651e-01\n",
            " -4.37937170e-01 -1.04230022e+00 -5.22557735e-01  2.19394624e-01\n",
            "  4.08481359e-01 -4.06680733e-01  9.88062099e-02 -4.59416747e-01\n",
            " -1.41646042e-01 -7.71786869e-01 -1.51751518e-01 -2.57236898e-01\n",
            " -3.52102727e-01 -9.17748749e-01  1.51759878e-01 -4.21681702e-01\n",
            " -2.84499615e-01 -4.52973247e-01 -7.68621787e-02  3.98133636e-01\n",
            "  5.24773411e-02  3.01995367e-01  8.32162201e-02 -1.74727693e-01\n",
            "  2.78176576e-01 -5.37484944e-01 -1.74596161e-01  1.58686489e-02\n",
            " -1.17461644e-01 -4.00991350e-01  1.54357597e-01  4.93369728e-01\n",
            "  4.75570885e-03  1.71253875e-01 -6.23435199e-01 -2.26678476e-01\n",
            " -1.88974142e-01  9.49520841e-02  1.59825146e-01 -7.99840093e-01\n",
            "  6.73583627e-01 -3.73749375e-01 -1.33263897e-02 -7.96823204e-02\n",
            "  6.05361342e-01  4.19661671e-01 -3.82374823e-01  1.28244713e-01\n",
            "  3.45430672e-01  3.35411191e-01  1.15200551e-03 -2.61717945e-01\n",
            " -1.58275217e-01 -1.63796484e-01  5.36331385e-02 -7.95977771e-01\n",
            " -1.79772794e-01 -1.10960536e-01  1.06551282e-01 -3.94078940e-01\n",
            "  7.01083094e-02  2.71831334e-01  2.19446525e-01 -2.73392409e-01\n",
            " -6.91800535e-01 -8.39871526e-01  3.36507201e-01  1.31039292e-01\n",
            " -4.62118894e-01  4.42734689e-01  8.00823569e-02 -5.82136177e-02\n",
            " -2.27672175e-01  2.54257828e-01  2.97381759e-01 -2.84668803e-01\n",
            " -2.37127036e-01  4.65973854e-01 -2.87309915e-01  8.39556158e-02\n",
            "  1.85184196e-01 -6.35847896e-02  1.06372438e-01 -3.89684409e-01\n",
            "  7.32663035e-01 -1.78993598e-01  1.53970659e-01 -4.35625106e-01\n",
            " -2.11648330e-01  1.15704149e-01  5.26291847e-01  4.05767471e-01\n",
            " -2.29366913e-01  1.76241502e-01  6.46697283e-01  2.89597601e-01\n",
            " -1.14568777e-01  4.17025059e-01 -6.18323758e-02 -4.19245422e-01\n",
            "  6.39347220e-03  4.80001718e-01 -5.53628087e-01  3.91104966e-01\n",
            " -7.94424042e-02 -4.90027368e-01 -5.99500835e-01  1.31106928e-01\n",
            " -6.90688044e-02 -1.09190620e-01 -6.48480892e-01 -9.79214385e-02\n",
            "  1.99177250e-01  3.72988015e-01  1.54091781e-02 -3.74426723e-01\n",
            "  2.66930372e-01  2.14621171e-01  3.84485126e-02  6.03905082e-01\n",
            " -1.70105398e-01 -1.23401627e-01 -1.07547903e+00 -2.92022884e-01\n",
            "  1.15199275e-01  2.42883787e-01  3.73331547e-01 -2.40751907e-01\n",
            "  2.75680959e-01  2.59956867e-01 -9.91009623e-02 -1.01354949e-01\n",
            " -1.72321051e-01 -4.77630943e-01  3.12474966e-01 -1.94662586e-01\n",
            " -1.68546811e-01  5.92755750e-02 -4.23029393e-01 -6.54500127e-01\n",
            " -5.53916276e-01 -6.33997977e-01  3.03505719e-01  4.80763763e-01\n",
            "  3.14049155e-01 -2.29396507e-01  1.73463359e-01 -4.44849469e-02\n",
            " -6.52564764e-01 -6.65893257e-02 -1.50510728e-01 -4.33215797e-01\n",
            " -7.47327089e-01 -1.07325569e-01  7.78287202e-02 -1.12681419e-01\n",
            " -2.95087874e-01  1.04869261e-01  1.58225000e-01 -1.38654768e-01\n",
            "  1.57759935e-01 -9.41067785e-02  5.66903412e-01 -2.69062780e-02\n",
            " -3.03335577e-01 -3.28021377e-01  1.60064831e-01  3.23403850e-02\n",
            "  4.81073111e-01  1.71401232e-01  3.39985251e-01 -3.72242182e-01\n",
            "  1.00810915e-01 -3.22372794e-01  7.09382147e-02  4.37615603e-01\n",
            " -2.21465200e-01  2.03177929e-01  8.95517692e-03  4.16294754e-01\n",
            " -1.19361468e-01 -3.34682316e-01 -2.07364291e-01  4.89711436e-03\n",
            " -3.89803559e-01  1.09296039e-01  2.59408861e-01  2.71951646e-01\n",
            "  5.15201837e-02 -2.31673419e-01 -1.81023896e-01  3.82934183e-01\n",
            "  2.38072291e-01 -1.07872374e-01  8.41428712e-02 -3.14010859e-01\n",
            "  3.63235742e-01 -1.47168010e-01  1.60225555e-02 -3.09319049e-01\n",
            "  1.22391500e-01 -2.39496529e-01 -3.11515719e-01  1.59494057e-01\n",
            "  4.02372301e-01 -9.70553398e-01 -6.97570890e-02 -3.87947023e-01\n",
            "  7.17286319e-02  6.08926415e-01 -1.83236361e-01  1.79574385e-01\n",
            " -5.48998952e-01 -7.94246346e-02 -3.88531208e-01  2.23971635e-01\n",
            " -3.72315943e-01 -1.44556895e-01  2.71172315e-01  9.19817090e-02\n",
            "  3.47889483e-01  3.79318446e-01  1.76484585e-02  2.64418155e-01\n",
            "  4.78373051e-01  2.56972820e-01 -1.26760364e-01  2.02527791e-01\n",
            " -4.45157945e-01  4.74086702e-01  3.38508010e-01  1.48214787e-01\n",
            " -7.08503202e-02  1.04295284e-01  7.36862049e-02 -2.08680496e-01\n",
            " -1.57621577e-02  2.52403677e-01 -1.10550612e-01 -2.36452103e-01\n",
            "  4.61657941e-01  4.81026530e-01 -7.44006872e-01  2.48987705e-01\n",
            " -3.95965517e-01 -2.70835400e-01 -2.35210389e-01  3.17068398e-01\n",
            "  2.23218992e-01 -2.47098312e-01  2.51257241e-01 -2.37080585e-02\n",
            "  2.36069024e-01  6.93424940e-01 -5.68225324e-01  1.84065312e-01\n",
            "  2.99440473e-01 -1.64064109e-01 -3.06320965e-01  4.10973042e-01\n",
            "  2.76521176e-01 -2.25385092e-02  1.33801967e-01 -3.45138431e-01\n",
            "  3.07657588e-02  5.08909941e-01  8.80382359e-02 -5.16217947e-01\n",
            " -4.03126096e-03  5.96261024e-02  3.29551339e-01  2.56163269e-01\n",
            "  3.93271178e-01 -2.70304710e-01  1.64560944e-01 -5.94246149e-01\n",
            "  6.65225267e-01  1.60393834e-01  2.87779987e-01  3.28129321e-01\n",
            "  3.28806564e-02 -1.76056221e-01  3.53646576e-01  4.73749518e-01\n",
            "  1.97473511e-01  7.99758434e-02 -1.51698530e-01  4.03110981e-01\n",
            "  5.53392231e-01  7.04780042e-01  1.76510453e-01 -3.37462932e-01\n",
            " -6.05611727e-02  7.10960865e-01 -7.01390207e-02 -6.68966591e-01\n",
            " -3.33828449e-01  8.88049975e-03  6.08134985e-01  3.13350618e-01\n",
            "  7.35987604e-01  1.07717484e-01  7.66705945e-02  6.01937950e-01\n",
            "  2.16976985e-01 -3.74704868e-01 -4.86179948e-01  3.46933842e-01\n",
            "  2.30107442e-01  1.65904522e-01 -5.10930300e-01 -4.17625278e-01\n",
            "  1.94164068e-01 -1.87642872e-01  4.14266530e-03 -2.65301601e-03\n",
            "  1.95566282e-01 -2.13505685e-01  1.74400583e-02 -2.47235984e-01\n",
            "  6.06311738e-01 -4.61056024e-01  2.39027608e-02 -2.27555692e-01\n",
            "  5.00128508e-01  1.44955456e-01  2.46581897e-01 -1.39955744e-01\n",
            "  4.95012403e-01 -4.65205550e-01 -2.84955442e-01  1.12784542e-01\n",
            "  8.47329199e-02 -4.64877822e-02 -2.29404032e-01 -2.73202300e-01\n",
            " -1.05650358e-01 -4.71498489e-01 -1.17786236e-01  4.75230485e-01\n",
            " -7.07125783e-01  4.58218493e-02  1.40601620e-01 -6.15765601e-02\n",
            "  6.31984323e-02  4.59126048e-02 -6.21835351e-01  5.26886046e-01\n",
            "  1.72362730e-01 -3.01937982e-02  6.50808513e-02  3.93551707e-01\n",
            " -5.55426180e-01 -5.30113041e-01  6.76962852e-01  5.04937053e-01\n",
            "  6.87227771e-02 -1.17642492e-01 -3.98603529e-01  3.43398690e-01\n",
            "  5.99215962e-02 -1.88133195e-01 -1.64465010e-01  1.15822386e-02\n",
            " -4.14652266e-02  4.86197099e-02 -2.36134663e-01 -4.77046341e-01\n",
            "  1.66320711e-01 -1.55077606e-01  3.84270072e-01  3.59261572e-01\n",
            " -7.68592596e-01 -4.60893840e-01 -2.76900887e-01 -4.84783858e-01\n",
            "  3.07743430e-01 -6.73858404e-01  1.22446604e-01  3.23136449e-01\n",
            " -6.08659834e-02 -3.85811806e-01  6.74338192e-02 -2.34986618e-01\n",
            " -1.76480755e-01 -1.47554740e-01  4.01461244e-01 -3.50412130e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. GloVe Embeddings\n",
        "\n",
        "Now let's use pre-trained GloVe embeddings:"
      ],
      "metadata": {
        "id": "pQqDCng2n2bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GloVe embeddings\n",
        "glove = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "def get_glove_embedding(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    word_embeddings = [glove[word] for word in words if word in glove]\n",
        "    return np.mean(word_embeddings, axis=0) if word_embeddings else np.zeros(glove.vector_size)\n",
        "\n",
        "# Get GloVe embeddings for all sentences\n",
        "glove_embeddings = [get_glove_embedding(sent) for sent in sentences]\n",
        "\n",
        "print(\"GloVe embedding shape:\", glove_embeddings[0].shape)\n",
        "print(glove_embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIvOLpfMnyP-",
        "outputId": "64cb75e4-9d06-4ef9-d3e5-b530dfbf6644"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "GloVe embedding shape: (100,)\n",
            "[-4.3515600e-02 -2.9748004e-02  5.9098202e-01 -2.4206194e-01\n",
            " -9.6999198e-02  3.5600525e-01 -1.7048240e-01  3.8083202e-01\n",
            " -4.9104899e-01 -2.9986900e-01  2.0948200e-01  1.4106001e-02\n",
            "  3.8480201e-01 -1.0425195e-02  2.0291999e-01  2.9041598e-02\n",
            "  4.3107802e-01 -1.0969679e-01 -1.7927799e-01 -3.6845797e-01\n",
            "  1.6791800e-01 -3.5751998e-02  3.2425421e-01 -9.8839596e-02\n",
            "  5.5196798e-01 -7.1866393e-02 -2.4172981e-01 -3.6806980e-01\n",
            " -1.7447004e-01  4.5199994e-02  6.3351199e-02  3.1589383e-01\n",
            "  2.1115419e-01  2.6616600e-01 -3.8537998e-02  3.2990918e-01\n",
            " -2.8460804e-02  4.0716800e-01  3.5629180e-01 -9.2135206e-02\n",
            " -4.0600601e-01 -2.9943421e-01  2.1148400e-01 -1.8706401e-01\n",
            "  5.9060035e-03  1.6642201e-01 -1.4540000e-01 -1.3599999e-01\n",
            "  7.7965088e-02 -4.8302460e-01 -1.1683513e-01  4.7059981e-03\n",
            "  2.7543801e-01  1.0413139e+00 -6.7047000e-01 -2.3747602e+00\n",
            " -5.9869200e-02 -1.7457598e-01  1.5867101e+00  5.2350998e-01\n",
            " -5.2707992e-02  8.7856799e-01 -1.8929639e-01  2.6198402e-01\n",
            "  6.8830407e-01  2.3603527e-01  1.0814881e-01  1.5297601e-01\n",
            "  2.8479920e-04  7.3887996e-02 -2.7271920e-01 -5.7255995e-02\n",
            "  4.3140113e-02 -3.4980202e-01 -1.3380200e-02  1.9747600e-01\n",
            " -3.9654601e-01  2.4630195e-02 -7.6616800e-01 -9.0893611e-02\n",
            "  5.7209396e-01  4.3316603e-02 -2.0023899e-01  6.0061611e-02\n",
            " -1.0079800e+00 -5.0270796e-01 -2.1407202e-02 -1.5248060e-01\n",
            "  6.8673559e-02 -4.9114000e-02  3.8079996e-02 -9.3939610e-02\n",
            " -1.0316000e-01  7.2310764e-01 -5.0655806e-01 -6.0803998e-02\n",
            " -3.5813600e-01 -8.6658001e-02  7.9335999e-01 -3.3110000e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. FastText Embeddings\n",
        "\n",
        "Let's use FastText embeddings:"
      ],
      "metadata": {
        "id": "rwS8sLWmnrEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained FastText embeddings\n",
        "fasttext = api.load(\"fasttext-wiki-news-subwords-300\")\n",
        "\n",
        "def get_fasttext_embedding(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    word_embeddings = [fasttext[word] for word in words if word in fasttext]\n",
        "    return np.mean(word_embeddings, axis=0) if word_embeddings else np.zeros(fasttext.vector_size)\n",
        "\n",
        "# Get FastText embeddings for all sentences\n",
        "fasttext_embeddings = [get_fasttext_embedding(sent) for sent in sentences]\n",
        "\n",
        "print(\"FastText embedding shape:\", fasttext_embeddings[0].shape)\n",
        "print(fasttext_embeddings[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2PMuvO9nrrO",
        "outputId": "8aab9c2e-5832-4ec0-990a-eda6574514a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "FastText embedding shape: (300,)\n",
            "[-1.07459910e-03 -3.25630009e-02  2.54664011e-02  6.10740017e-03\n",
            "  2.71326397e-02 -2.97526922e-02  2.36619990e-02 -1.69375986e-01\n",
            " -2.46400796e-02  3.74299996e-02 -4.69814017e-02 -1.43874720e-01\n",
            "  6.30912036e-02 -1.86050013e-02  1.07885990e-02  1.56834014e-02\n",
            "  1.31402612e-01 -7.43899960e-03  7.43768066e-02 -2.35512014e-02\n",
            " -2.01811995e-02 -1.78665612e-02  1.87217183e-02  2.70860586e-02\n",
            "  5.58306053e-02 -4.29212023e-03  6.18999964e-03  2.90717967e-02\n",
            "  7.63084963e-02 -1.44822001e-02 -1.06967408e-02 -2.07982007e-02\n",
            "  1.90843996e-02  1.43086817e-02 -5.06734028e-02 -7.34577924e-02\n",
            "  1.83796026e-02 -3.22851241e-02  1.50565337e-02 -4.59660590e-02\n",
            " -2.22694799e-02 -7.13122040e-02 -3.31973806e-02  3.85112013e-03\n",
            "  5.12128044e-03  6.67500049e-02  1.05209192e-02  1.95667129e-02\n",
            " -2.47640023e-03  2.23735608e-02  6.31771535e-02  4.27426770e-02\n",
            "  3.72897983e-02 -2.54235603e-02 -1.22278549e-01 -1.91269591e-02\n",
            " -4.00395989e-02 -8.88400059e-03 -1.19473197e-01 -1.88320391e-02\n",
            " -8.38700030e-03 -4.87207063e-02  2.75896013e-01  1.48397209e-02\n",
            "  1.87351201e-02  1.33471992e-02  1.05094602e-02  6.69599860e-04\n",
            " -2.64574345e-02 -1.67283993e-02  1.38512002e-02 -5.93699981e-03\n",
            "  1.94864012e-02 -2.99460068e-03  7.66929984e-03 -2.36544795e-02\n",
            " -4.69356813e-02  3.40063982e-02 -1.76300050e-03 -1.74779408e-02\n",
            "  2.15645949e-03 -4.47077975e-02  2.31311973e-02  8.08215961e-02\n",
            "  1.68084039e-03 -4.00940403e-02 -4.41537704e-03 -7.45799989e-02\n",
            "  2.78351996e-02 -3.64162028e-03 -9.49400105e-03 -8.78983922e-03\n",
            " -1.92011997e-01  9.17940214e-03  7.39299953e-02  6.40784055e-02\n",
            "  4.45928052e-02  5.77159971e-03  7.29800016e-03  2.59763189e-02\n",
            "  1.59585811e-02  1.62614789e-02  4.45939973e-02  3.10163982e-02\n",
            "  3.74400010e-03 -2.12550804e-01 -3.12442388e-02  2.32724585e-02\n",
            "  2.00351998e-02  8.79975967e-03 -1.48217997e-03  1.17081150e-01\n",
            "  8.19949955e-02 -3.19010019e-02 -2.14026812e-02 -2.64042802e-02\n",
            "  2.97053996e-02  1.84173994e-02 -4.17592004e-02  1.42267998e-02\n",
            "  1.55850006e-02  3.90625186e-02  1.39453996e-03 -2.13351604e-02\n",
            " -9.63101983e-02  2.62226816e-02  3.03239226e-02 -1.83678597e-01\n",
            " -1.08440211e-02  1.43630594e-01  3.91291976e-02  9.55018122e-03\n",
            " -1.32242395e-02  3.69166024e-02 -1.68566015e-02 -7.53460627e-04\n",
            " -2.76312772e-02  1.34907797e-01  2.92202588e-02  1.36178788e-02\n",
            "  1.00575192e-02  3.87523994e-02 -6.59552123e-03 -3.77719998e-02\n",
            " -4.34093997e-02 -2.37904005e-02 -3.87946027e-03  1.59430411e-02\n",
            "  1.18068997e-02 -1.61700007e-02 -1.57038011e-02  1.58572383e-02\n",
            " -3.88148054e-03 -1.09865800e-01 -1.45458002e-02  8.42760038e-03\n",
            "  7.95219839e-03 -2.49265581e-02 -4.17173170e-02  1.15962010e-02\n",
            " -3.87119921e-03 -9.00279731e-04  8.26760102e-03  2.73512006e-02\n",
            " -1.46418121e-02  8.55091959e-03  1.21375930e-03  2.75859982e-03\n",
            " -2.03183610e-02 -6.37983996e-03 -3.80473211e-02 -5.87021932e-03\n",
            " -3.04955598e-02  4.52670008e-02 -1.27774598e-02  5.60933538e-02\n",
            " -1.17512001e-03 -7.73419952e-03 -5.66624850e-03  7.89012015e-03\n",
            " -4.53920010e-03 -1.61244012e-02 -6.37339940e-03 -5.38171232e-02\n",
            " -5.94979944e-03 -3.66333202e-02 -2.14148425e-02  2.13143989e-01\n",
            " -9.22459923e-03 -4.95936014e-02 -9.96948034e-03  8.27003941e-02\n",
            " -1.13775991e-01 -1.59901939e-03  1.16482591e-02  3.73310000e-02\n",
            " -1.35706812e-02  4.96365987e-02  9.94891953e-03  2.79495008e-02\n",
            " -2.17263788e-01  1.51353598e-01  3.33085246e-02 -5.15033603e-02\n",
            "  2.08043936e-03 -5.94020076e-03  9.59836133e-03 -2.93193990e-03\n",
            " -2.04400010e-02 -4.57012057e-02  2.30212003e-01 -2.13728379e-02\n",
            "  3.81288007e-02 -1.32704002e-03 -9.53759998e-03  1.08153997e-02\n",
            "  3.48247960e-02 -1.26640091e-03  4.31829989e-02 -2.20648013e-02\n",
            "  2.14432403e-02 -1.05775986e-02 -2.48329993e-02  1.78155988e-01\n",
            "  1.25878798e-02  1.69273000e-02  2.14762408e-02  1.21363603e-01\n",
            "  1.36457998e-02 -3.40713784e-02  2.39365995e-02 -1.21272996e-01\n",
            " -4.36122008e-02 -1.21726003e-02 -7.92200025e-03 -1.48943989e-02\n",
            "  2.27973983e-02  5.31146415e-02 -3.64856012e-02 -8.01106170e-03\n",
            "  1.30160853e-01 -9.64465830e-03 -2.00030003e-02  1.56772020e-03\n",
            " -2.19310001e-01  3.00246775e-02  4.83460026e-03  6.15879986e-03\n",
            " -2.80354172e-02 -5.20254187e-02  1.39124887e-02 -2.22939998e-02\n",
            "  3.49576026e-03  5.78764006e-02 -2.33139992e-02 -4.13744375e-02\n",
            " -3.64400272e-04  4.66600060e-04 -6.27275906e-04  2.95354780e-02\n",
            " -2.48723403e-02 -9.14380047e-03  9.68156196e-03  2.29419954e-02\n",
            " -9.31202449e-05  2.02880055e-03  2.21152026e-02  1.26664015e-02\n",
            " -1.69222411e-02  9.67399974e-04 -6.36029989e-02  1.56759992e-01\n",
            " -2.18206003e-01 -5.02647981e-02  7.84536004e-02 -5.01786992e-02\n",
            "  1.32200792e-02 -1.11368001e-02  6.57367986e-03 -4.59002033e-02\n",
            " -2.57460168e-03  3.87975983e-02  5.77444024e-02 -6.40573958e-03\n",
            "  1.07500002e-01  5.59178088e-03 -4.51165996e-02 -1.61343604e-01\n",
            " -8.97173397e-03  1.37773603e-02  1.28680095e-03 -4.96039912e-03\n",
            " -1.30205974e-02 -5.48299868e-03  1.63694415e-02  3.49116810e-02\n",
            " -1.18428003e-02  3.30239837e-03  4.90293987e-02  4.87518609e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. Comparing Embeddings\n",
        "\n",
        "Let's compare the similarities between sentences using different embedding types:"
      ],
      "metadata": {
        "id": "ZfJrFhTGnk1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "def print_most_similar(embeddings, sentences):\n",
        "    similarities = [[cosine_similarity(e1, e2) for e2 in embeddings] for e1 in embeddings]\n",
        "    for i, sent in enumerate(sentences):\n",
        "        most_similar = max(range(len(sentences)), key=lambda x: similarities[i][x] if x != i else -1)\n",
        "        print(f\"'{sent}' is most similar to '{sentences[most_similar]}'\")\n",
        "\n",
        "print(\"BERT similarities:\")\n",
        "print_most_similar(bert_embeddings, sentences)\n",
        "\n",
        "print(\"\\nGloVe similarities:\")\n",
        "print_most_similar(glove_embeddings, sentences)\n",
        "\n",
        "print(\"\\nFastText similarities:\")\n",
        "print_most_similar(fasttext_embeddings, sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2f_gK_fnge-",
        "outputId": "a7bf1b78-e10d-4587-ca01-4e3e9f336600"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT similarities:\n",
            "'The cat sat on the mat.' is most similar to 'It's raining cats and dogs.'\n",
            "'Dogs are man's best friend.' is most similar to 'Actions speak louder than words.'\n",
            "'It's raining cats and dogs.' is most similar to 'The cat sat on the mat.'\n",
            "'The early bird catches the worm.' is most similar to 'The apple doesn't fall far from the tree.'\n",
            "'Actions speak louder than words.' is most similar to 'A picture is worth a thousand words.'\n",
            "'A picture is worth a thousand words.' is most similar to 'Actions speak louder than words.'\n",
            "'Don't judge a book by its cover.' is most similar to 'A picture is worth a thousand words.'\n",
            "'The apple doesn't fall far from the tree.' is most similar to 'All that glitters is not gold.'\n",
            "'Time flies like an arrow.' is most similar to 'A picture is worth a thousand words.'\n",
            "'All that glitters is not gold.' is most similar to 'A picture is worth a thousand words.'\n",
            "\n",
            "GloVe similarities:\n",
            "'The cat sat on the mat.' is most similar to 'The early bird catches the worm.'\n",
            "'Dogs are man's best friend.' is most similar to 'Time flies like an arrow.'\n",
            "'It's raining cats and dogs.' is most similar to 'Dogs are man's best friend.'\n",
            "'The early bird catches the worm.' is most similar to 'The cat sat on the mat.'\n",
            "'Actions speak louder than words.' is most similar to 'All that glitters is not gold.'\n",
            "'A picture is worth a thousand words.' is most similar to 'Don't judge a book by its cover.'\n",
            "'Don't judge a book by its cover.' is most similar to 'A picture is worth a thousand words.'\n",
            "'The apple doesn't fall far from the tree.' is most similar to 'The cat sat on the mat.'\n",
            "'Time flies like an arrow.' is most similar to 'The cat sat on the mat.'\n",
            "'All that glitters is not gold.' is most similar to 'Time flies like an arrow.'\n",
            "\n",
            "FastText similarities:\n",
            "'The cat sat on the mat.' is most similar to 'The early bird catches the worm.'\n",
            "'Dogs are man's best friend.' is most similar to 'All that glitters is not gold.'\n",
            "'It's raining cats and dogs.' is most similar to 'Dogs are man's best friend.'\n",
            "'The early bird catches the worm.' is most similar to 'The apple doesn't fall far from the tree.'\n",
            "'Actions speak louder than words.' is most similar to 'All that glitters is not gold.'\n",
            "'A picture is worth a thousand words.' is most similar to 'Don't judge a book by its cover.'\n",
            "'Don't judge a book by its cover.' is most similar to 'A picture is worth a thousand words.'\n",
            "'The apple doesn't fall far from the tree.' is most similar to 'The early bird catches the worm.'\n",
            "'Time flies like an arrow.' is most similar to 'The early bird catches the worm.'\n",
            "'All that glitters is not gold.' is most similar to 'Dogs are man's best friend.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "This notebook demonstrates how to use pre-trained BERT, GloVe, and FastText models to generate embeddings for sentences. We've seen how to load these models, generate embeddings, compare similarities, and visualize the results. Note the differences in how each model represents the sentences and captures their similarities."
      ],
      "metadata": {
        "id": "wFdAiX34nNWm"
      }
    }
  ]
}